name: News Agent (politics)

on:
  schedule:
    # 6am, 9am, 12pm, 3pm, 6pm EST (Detroit) = 11, 14, 17, 20, 23 UTC
    - cron: "0 11,14,17,20,23 * * *"
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Debug - List files
        run: |
          echo "Current directory:"
          pwd
          echo "Files in current directory:"
          ls -la
          echo "Checking for news_picker.py:"
          test -f news_picker.py && echo "news_picker.py EXISTS" || echo "news_picker.py MISSING"

      - name: Restore Google service account JSON
        run: |
          mkdir -p credentials
          echo "${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON_B64 }}" | base64 --decode > credentials/service_account.json
          python -m json.tool credentials/service_account.json > /dev/null || (echo "Invalid JSON" && exit 1)

      - name: Run generator (auto politics)
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          NEWSDATA_API_KEY: ${{ secrets.NEWSDATA_API_KEY }}
          GOOGLE_SHEETS_KEY: ${{ secrets.GOOGLE_SHEETS_KEY }}
          GOOGLE_SERVICE_ACCOUNT_JSON_PATH: credentials/service_account.json
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          AI_HORDE_API_KEY: ${{ secrets.AI_HORDE_API_KEY }}
        run: |
          python generate_segments.py --auto --country us --topic politics --duration 3.5 --model "gemini-2.5-flash" --max-words 15 --min-words 10

      - name: Install FFmpeg and fonts
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg fonts-dejavu-core
          ffmpeg -version

      - name: Generate video
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          NEWSDATA_API_KEY: ${{ secrets.NEWSDATA_API_KEY }}
          GOOGLE_SHEETS_KEY: ${{ secrets.GOOGLE_SHEETS_KEY }}
          GOOGLE_SERVICE_ACCOUNT_JSON_PATH: credentials/service_account.json
        run: |
          mkdir -p credentials generated
          echo "${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON_B64 }}" | base64 --decode > credentials/service_account.json
          python fetch_segments_for_video.py --output-dir generated
          python video/make_video.py

      - name: Generate caption with AI
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python generate_caption.py generated
          TIMESTAMP=$(date +%s)
          export TIMESTAMP
          python generate_video_metadata.py
          echo "$TIMESTAMP" > generated/.timestamp

      # Authenticate first so subsequent CLI setup and commands pick up creds
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      - name: Verify GCP auth and bucket access (preflight)
        env:
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
        run: |
          echo "Active gcloud account:"
          gcloud auth list --filter=status:ACTIVE
          echo "Current project: $(gcloud config get-value project 2>/dev/null)"
          echo "Listing bucket metadata (if accessible): gs://$GCS_BUCKET"
          gcloud storage ls -b gs://$GCS_BUCKET || echo "Note: Could not list bucket metadata; continuing to upload step"

      - name: Show IAM fix commands (if upload gets 403)
        if: always()
        env:
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
        run: |
          # Derive the service account email from the credentials file created by the auth action
          SA_EMAIL=$(python -c "import json, os; p=os.environ.get('GOOGLE_APPLICATION_CREDENTIALS') or os.environ.get('GOOGLE_GHA_CREDS_PATH'); print(json.load(open(p))['client_email'])")
          echo "If the next step fails with 403, grant these roles to the service account on your bucket:"
          echo "Service Account: ${SA_EMAIL}"
          echo "Bucket: gs://${GCS_BUCKET}"
          echo "---- Run in Cloud Shell (copy/paste) ----"
          echo "gcloud storage buckets add-iam-policy-binding gs://${GCS_BUCKET} --member=serviceAccount:${SA_EMAIL} --role=roles/storage.objectCreator"
          echo "gcloud storage buckets add-iam-policy-binding gs://${GCS_BUCKET} --member=serviceAccount:${SA_EMAIL} --role=roles/storage.objectViewer"
          echo "# Alternatively, a single broader role:"
          echo "# gcloud storage buckets add-iam-policy-binding gs://${GCS_BUCKET} --member=serviceAccount:${SA_EMAIL} --role=roles/storage.objectAdmin"

      - name: Upload video to Google Cloud Storage
        run: |
          # Copy final video to generated folder with timestamp
          TIMESTAMP=$(cat generated/.timestamp)
          cp output/final.mp4 generated/news_video_${TIMESTAMP}.mp4
          
          # Upload to GCS (triggers Cloud Function automatically)
          # Use gcloud storage (recommended with github-actions/auth) instead of gsutil
          gcloud storage cp generated/news_video_${TIMESTAMP}.mp4 gs://${{ secrets.GCS_BUCKET }}/incoming/
          # Upload companion metadata JSON if present
          if [ -f generated/news_video_${TIMESTAMP}.json ]; then
            gcloud storage cp generated/news_video_${TIMESTAMP}.json gs://${{ secrets.GCS_BUCKET }}/incoming/
          fi
          
          echo "âœ… Video uploaded to GCS - Cloud Function will handle posting"
          echo "Video: gs://${{ secrets.GCS_BUCKET }}/incoming/news_video_${TIMESTAMP}.mp4"

      - name: Upload video artifact (backup)
        uses: actions/upload-artifact@v4
        with:
          name: news-video-${{ github.run_number }}
          path: |
            generated/news_video_*.mp4
            generated/caption.json
          retention-days: 30

      - name: Build Cloud Function (gcs-to-social)
        run: |
          mkdir -p build/gcs-to-social
          cp functions/gcs-to-social/main.py build/gcs-to-social/
          cp functions/gcs-to-social/requirements.txt build/gcs-to-social/
          cp functions/gcs-to-social/caption_utils.py build/gcs-to-social/
          cd build/gcs-to-social && zip -r ../gcs-to-social.zip .

      - name: Deploy Cloud Function (gcs-to-social)
        run: |
          gcloud functions deploy gcs-to-social \
            --region=us-central1 \
            --runtime=python311 \
            --entry-point=gcs_to_social \
            --trigger-bucket=${{ secrets.GCS_BUCKET }} \
            --memory=1Gi \
            --timeout=540s \
            --retry \
            --set-secrets=FACEBOOK_PAGE_TOKEN=FACEBOOK_PAGE_TOKEN:latest,YOUTUBE_CREDENTIALS_JSON=YOUTUBE_CREDENTIALS_JSON:latest,GEMINI_API_KEY=GEMINI_API_KEY:latest \
            --source=build/gcs-to-social

